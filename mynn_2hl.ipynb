{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape = (2, 400)\n",
      "Y.shape = (1, 400)\n"
     ]
    }
   ],
   "source": [
    "X = np.random.randint(2, size = (2, 400)) # creo una matrice con due numeri (0,1), su 2 colonne e 5 linee\n",
    "Y = np.logical_xor(X[0],X[1]) # creo delle coppie tra le due linee della matrice X (restituisci True se \"or\" is True)\n",
    "Y = Y.reshape(1,X.shape[1])*1 # forziamo la macchina a capire che per l'output voglio una linea e 5 colonne. Moltiplico per 1 per trsaformare True et False en 0 et 1\n",
    "\n",
    "#print(X)\n",
    "print(f\"X.shape = {X.shape}\")\n",
    "# print(Y)\n",
    "print(f\"Y.shape = {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure du reseaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layer = 2 units (n_x)\n",
      "Hidden layer 1 = 3 units (n_h1)\n",
      "Hidden layer 2 = 3 units (n_h2)\n",
      "Output layer = 1 output (n_y)\n",
      "\n",
      "NN structure = {'n_x': 2, 'n_h1': 3, 'n_h2': 3, 'n_y': 1}\n"
     ]
    }
   ],
   "source": [
    "n_x = int(X.shape[0]) # n° of inputs units\n",
    "print(f'Input layer = {n_x} units (n_x)')\n",
    "n_h1 = 3 # n° of neurones dans l'hidden layer 1\n",
    "print(f'Hidden layer 1 = {n_h1} units (n_h1)')\n",
    "n_h2 = 3 # n° of neurones dans l'hidden layer 2\n",
    "print(f'Hidden layer 2 = {n_h2} units (n_h2)')\n",
    "n_y = int(Y.shape[0]) # n° of output units\n",
    "print(f'Output layer = {n_y} output (n_y)')\n",
    "nn_structure = {'n_x':n_x,'n_h1':n_h1,'n_h2':n_h2,'n_y':n_y}\n",
    "print()\n",
    "print(f'NN structure = {nn_structure}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation des parametres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(n_x,n_h1,n_h2,n_y):\n",
    "    \n",
    "    '''\n",
    "    Function qui inizialize mes parametres\n",
    "    \n",
    "    Weight initialisés random, Bias initialisés à zero\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    \n",
    "    w1 = np.random.randn(n_h1,n_x) / np.sqrt(n_x)\n",
    "    w2 = np.random.randn(n_h2,n_h1) / np.sqrt(n_h1)\n",
    "    w3 = np.random.randn(n_y,n_h2) / np.sqrt(n_h2)\n",
    "    b1 = np.zeros((n_h1,1))\n",
    "    b2 = np.zeros((n_h2,1))\n",
    "    b3 = np.zeros((n_y,1))\n",
    "    \n",
    "    params = {'w1':w1, 'w2':w2, 'w3':w3, 'b1':b1, 'b2':b2, 'b3':b3}\n",
    "    \n",
    "    print(f'w1.shape = {w1.shape}')\n",
    "    print(f'w2.shape = {w2.shape}')\n",
    "    print(f'w3.shape = {w3.shape}')\n",
    "    print(f'b1.shape = {b1.shape}')\n",
    "    print(f'b2.shape = {b2.shape}')\n",
    "    print(f'b3.shape = {b3.shape}')\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1.shape = (3, 2)\n",
      "w2.shape = (3, 3)\n",
      "w3.shape = (1, 3)\n",
      "b1.shape = (3, 1)\n",
      "b2.shape = (3, 1)\n",
      "b3.shape = (1, 1)\n"
     ]
    }
   ],
   "source": [
    "params = init_params(n_x,n_h1,n_h2,n_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \n",
    "    '''\n",
    "    Fonction d'activation sigmoid\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, params):\n",
    "\n",
    "    '''\n",
    "    Fonction de forward propagation\n",
    "    \n",
    "    On recupere les parametres initialisés pour calculer la fonction de pre-activation Z\n",
    "\n",
    "    '''\n",
    "    w1 = params['w1'] \n",
    "    w2 = params['w2']\n",
    "    w3 = params['w3']\n",
    "    b1 = params['b1']\n",
    "    b2 = params['b2']\n",
    "    b3 = params['b3']\n",
    "    \n",
    "    z1 = np.dot(w1,X)+b1\n",
    "    a1 = sigmoid(z1)\n",
    "    z2 = np.dot(w2,a1)+b2\n",
    "    a2 = sigmoid(z2)\n",
    "    z3 = np.dot(w3,a2)+b3\n",
    "    a3 = sigmoid(z3)\n",
    "    \n",
    "    cache = {'z1':z1, 'z2':z2, 'z3':z3, 'a1':a1, 'a2':a2, 'a3':a3}\n",
    "    \n",
    "    #print(f'a1.shape = {a1.shape}')\n",
    "    #print(f'a2.shape = {a2.shape}')\n",
    "    #print(f'a3.shape = {a3.shape}')\n",
    "    \n",
    "    return cache, a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'z1': array([[ 0.28295388,  1.24737338,  0.        , ...,  1.24737338,\n",
       "           1.24737338,  0.28295388],\n",
       "         [ 1.58455078,  0.69207227,  0.        , ...,  0.69207227,\n",
       "           0.69207227,  1.58455078],\n",
       "         [-0.69103982,  1.32056292,  0.        , ...,  1.32056292,\n",
       "           1.32056292, -0.69103982]]),\n",
       "  'z2': array([[0.22040291, 0.32085349, 0.20077712, ..., 0.32085349, 0.32085349,\n",
       "          0.22040291],\n",
       "         [0.48446934, 0.90227618, 0.57992398, ..., 0.90227618, 0.90227618,\n",
       "          0.48446934],\n",
       "         [0.39440604, 0.59041348, 0.3829495 , ..., 0.59041348, 0.59041348,\n",
       "          0.39440604]]),\n",
       "  'z3': array([[0.56992503, 0.64910174, 0.58850759, 0.63443955, 0.64910174,\n",
       "          0.63443955, 0.64910174, 0.58850759, 0.63443955, 0.58850759,\n",
       "          0.58850759, 0.64910174, 0.64910174, 0.58850759, 0.64910174,\n",
       "          0.58850759, 0.64910174, 0.58850759, 0.56992503, 0.58850759,\n",
       "          0.56992503, 0.56992503, 0.64910174, 0.63443955, 0.56992503,\n",
       "          0.56992503, 0.58850759, 0.64910174, 0.63443955, 0.56992503,\n",
       "          0.63443955, 0.56992503, 0.58850759, 0.63443955, 0.58850759,\n",
       "          0.63443955, 0.64910174, 0.64910174, 0.64910174, 0.64910174,\n",
       "          0.63443955, 0.56992503, 0.63443955, 0.63443955, 0.56992503,\n",
       "          0.58850759, 0.63443955, 0.58850759, 0.56992503, 0.64910174,\n",
       "          0.63443955, 0.58850759, 0.63443955, 0.56992503, 0.58850759,\n",
       "          0.64910174, 0.58850759, 0.56992503, 0.56992503, 0.63443955,\n",
       "          0.64910174, 0.58850759, 0.63443955, 0.58850759, 0.58850759,\n",
       "          0.56992503, 0.58850759, 0.58850759, 0.64910174, 0.56992503,\n",
       "          0.64910174, 0.56992503, 0.64910174, 0.63443955, 0.64910174,\n",
       "          0.63443955, 0.63443955, 0.58850759, 0.64910174, 0.63443955,\n",
       "          0.64910174, 0.63443955, 0.58850759, 0.63443955, 0.64910174,\n",
       "          0.58850759, 0.58850759, 0.64910174, 0.56992503, 0.56992503,\n",
       "          0.58850759, 0.56992503, 0.64910174, 0.63443955, 0.56992503,\n",
       "          0.58850759, 0.63443955, 0.58850759, 0.64910174, 0.64910174,\n",
       "          0.64910174, 0.64910174, 0.56992503, 0.56992503, 0.58850759,\n",
       "          0.64910174, 0.58850759, 0.64910174, 0.63443955, 0.63443955,\n",
       "          0.58850759, 0.64910174, 0.56992503, 0.58850759, 0.63443955,\n",
       "          0.56992503, 0.63443955, 0.63443955, 0.56992503, 0.56992503,\n",
       "          0.63443955, 0.56992503, 0.63443955, 0.56992503, 0.63443955,\n",
       "          0.58850759, 0.64910174, 0.56992503, 0.63443955, 0.56992503,\n",
       "          0.56992503, 0.58850759, 0.64910174, 0.56992503, 0.64910174,\n",
       "          0.58850759, 0.63443955, 0.58850759, 0.56992503, 0.58850759,\n",
       "          0.56992503, 0.58850759, 0.64910174, 0.56992503, 0.58850759,\n",
       "          0.64910174, 0.58850759, 0.58850759, 0.58850759, 0.63443955,\n",
       "          0.58850759, 0.56992503, 0.64910174, 0.58850759, 0.63443955,\n",
       "          0.56992503, 0.56992503, 0.63443955, 0.64910174, 0.58850759,\n",
       "          0.56992503, 0.58850759, 0.63443955, 0.63443955, 0.56992503,\n",
       "          0.56992503, 0.58850759, 0.58850759, 0.56992503, 0.64910174,\n",
       "          0.58850759, 0.63443955, 0.56992503, 0.56992503, 0.58850759,\n",
       "          0.64910174, 0.64910174, 0.63443955, 0.56992503, 0.58850759,\n",
       "          0.63443955, 0.64910174, 0.64910174, 0.64910174, 0.56992503,\n",
       "          0.56992503, 0.58850759, 0.63443955, 0.64910174, 0.56992503,\n",
       "          0.64910174, 0.58850759, 0.56992503, 0.64910174, 0.58850759,\n",
       "          0.64910174, 0.64910174, 0.64910174, 0.63443955, 0.56992503,\n",
       "          0.56992503, 0.56992503, 0.63443955, 0.63443955, 0.63443955,\n",
       "          0.56992503, 0.64910174, 0.64910174, 0.64910174, 0.64910174,\n",
       "          0.56992503, 0.56992503, 0.63443955, 0.63443955, 0.58850759,\n",
       "          0.56992503, 0.58850759, 0.64910174, 0.63443955, 0.56992503,\n",
       "          0.63443955, 0.64910174, 0.63443955, 0.63443955, 0.63443955,\n",
       "          0.58850759, 0.56992503, 0.56992503, 0.63443955, 0.56992503,\n",
       "          0.63443955, 0.58850759, 0.64910174, 0.63443955, 0.58850759,\n",
       "          0.58850759, 0.58850759, 0.63443955, 0.58850759, 0.56992503,\n",
       "          0.64910174, 0.63443955, 0.64910174, 0.63443955, 0.56992503,\n",
       "          0.64910174, 0.56992503, 0.58850759, 0.58850759, 0.58850759,\n",
       "          0.63443955, 0.64910174, 0.63443955, 0.58850759, 0.63443955,\n",
       "          0.56992503, 0.58850759, 0.63443955, 0.63443955, 0.64910174,\n",
       "          0.63443955, 0.63443955, 0.63443955, 0.56992503, 0.56992503,\n",
       "          0.64910174, 0.64910174, 0.63443955, 0.63443955, 0.63443955,\n",
       "          0.63443955, 0.64910174, 0.63443955, 0.64910174, 0.64910174,\n",
       "          0.56992503, 0.58850759, 0.56992503, 0.58850759, 0.63443955,\n",
       "          0.63443955, 0.64910174, 0.56992503, 0.63443955, 0.64910174,\n",
       "          0.63443955, 0.64910174, 0.64910174, 0.64910174, 0.64910174,\n",
       "          0.56992503, 0.58850759, 0.58850759, 0.56992503, 0.64910174,\n",
       "          0.64910174, 0.58850759, 0.63443955, 0.58850759, 0.56992503,\n",
       "          0.64910174, 0.58850759, 0.64910174, 0.58850759, 0.63443955,\n",
       "          0.56992503, 0.56992503, 0.58850759, 0.58850759, 0.63443955,\n",
       "          0.63443955, 0.64910174, 0.56992503, 0.63443955, 0.58850759,\n",
       "          0.63443955, 0.56992503, 0.58850759, 0.56992503, 0.58850759,\n",
       "          0.63443955, 0.63443955, 0.64910174, 0.58850759, 0.64910174,\n",
       "          0.58850759, 0.56992503, 0.63443955, 0.64910174, 0.64910174,\n",
       "          0.56992503, 0.63443955, 0.64910174, 0.58850759, 0.64910174,\n",
       "          0.56992503, 0.64910174, 0.63443955, 0.58850759, 0.58850759,\n",
       "          0.63443955, 0.64910174, 0.58850759, 0.64910174, 0.63443955,\n",
       "          0.63443955, 0.64910174, 0.64910174, 0.64910174, 0.56992503,\n",
       "          0.58850759, 0.64910174, 0.56992503, 0.64910174, 0.56992503,\n",
       "          0.58850759, 0.64910174, 0.63443955, 0.63443955, 0.64910174,\n",
       "          0.64910174, 0.56992503, 0.63443955, 0.63443955, 0.64910174,\n",
       "          0.58850759, 0.58850759, 0.64910174, 0.64910174, 0.56992503,\n",
       "          0.64910174, 0.64910174, 0.64910174, 0.58850759, 0.58850759,\n",
       "          0.56992503, 0.63443955, 0.56992503, 0.56992503, 0.56992503,\n",
       "          0.58850759, 0.58850759, 0.56992503, 0.63443955, 0.63443955,\n",
       "          0.63443955, 0.56992503, 0.56992503, 0.63443955, 0.63443955,\n",
       "          0.64910174, 0.58850759, 0.64910174, 0.56992503, 0.63443955,\n",
       "          0.56992503, 0.63443955, 0.64910174, 0.64910174, 0.56992503]]),\n",
       "  'a1': array([[0.57027026, 0.77684485, 0.5       , ..., 0.77684485, 0.77684485,\n",
       "          0.57027026],\n",
       "         [0.82984805, 0.66642775, 0.5       , ..., 0.66642775, 0.66642775,\n",
       "          0.82984805],\n",
       "         [0.3338018 , 0.78927535, 0.5       , ..., 0.78927535, 0.78927535,\n",
       "          0.3338018 ]]),\n",
       "  'a2': array([[0.55487875, 0.57953224, 0.55002634, ..., 0.57953224, 0.57953224,\n",
       "          0.55487875],\n",
       "         [0.61880269, 0.71141703, 0.64104991, ..., 0.71141703, 0.71141703,\n",
       "          0.61880269],\n",
       "         [0.59734291, 0.64346001, 0.59458429, ..., 0.64346001, 0.64346001,\n",
       "          0.59734291]]),\n",
       "  'a3': array([[0.63874588, 0.65680801, 0.64302264, 0.65349544, 0.65680801,\n",
       "          0.65349544, 0.65680801, 0.64302264, 0.65349544, 0.64302264,\n",
       "          0.64302264, 0.65680801, 0.65680801, 0.64302264, 0.65680801,\n",
       "          0.64302264, 0.65680801, 0.64302264, 0.63874588, 0.64302264,\n",
       "          0.63874588, 0.63874588, 0.65680801, 0.65349544, 0.63874588,\n",
       "          0.63874588, 0.64302264, 0.65680801, 0.65349544, 0.63874588,\n",
       "          0.65349544, 0.63874588, 0.64302264, 0.65349544, 0.64302264,\n",
       "          0.65349544, 0.65680801, 0.65680801, 0.65680801, 0.65680801,\n",
       "          0.65349544, 0.63874588, 0.65349544, 0.65349544, 0.63874588,\n",
       "          0.64302264, 0.65349544, 0.64302264, 0.63874588, 0.65680801,\n",
       "          0.65349544, 0.64302264, 0.65349544, 0.63874588, 0.64302264,\n",
       "          0.65680801, 0.64302264, 0.63874588, 0.63874588, 0.65349544,\n",
       "          0.65680801, 0.64302264, 0.65349544, 0.64302264, 0.64302264,\n",
       "          0.63874588, 0.64302264, 0.64302264, 0.65680801, 0.63874588,\n",
       "          0.65680801, 0.63874588, 0.65680801, 0.65349544, 0.65680801,\n",
       "          0.65349544, 0.65349544, 0.64302264, 0.65680801, 0.65349544,\n",
       "          0.65680801, 0.65349544, 0.64302264, 0.65349544, 0.65680801,\n",
       "          0.64302264, 0.64302264, 0.65680801, 0.63874588, 0.63874588,\n",
       "          0.64302264, 0.63874588, 0.65680801, 0.65349544, 0.63874588,\n",
       "          0.64302264, 0.65349544, 0.64302264, 0.65680801, 0.65680801,\n",
       "          0.65680801, 0.65680801, 0.63874588, 0.63874588, 0.64302264,\n",
       "          0.65680801, 0.64302264, 0.65680801, 0.65349544, 0.65349544,\n",
       "          0.64302264, 0.65680801, 0.63874588, 0.64302264, 0.65349544,\n",
       "          0.63874588, 0.65349544, 0.65349544, 0.63874588, 0.63874588,\n",
       "          0.65349544, 0.63874588, 0.65349544, 0.63874588, 0.65349544,\n",
       "          0.64302264, 0.65680801, 0.63874588, 0.65349544, 0.63874588,\n",
       "          0.63874588, 0.64302264, 0.65680801, 0.63874588, 0.65680801,\n",
       "          0.64302264, 0.65349544, 0.64302264, 0.63874588, 0.64302264,\n",
       "          0.63874588, 0.64302264, 0.65680801, 0.63874588, 0.64302264,\n",
       "          0.65680801, 0.64302264, 0.64302264, 0.64302264, 0.65349544,\n",
       "          0.64302264, 0.63874588, 0.65680801, 0.64302264, 0.65349544,\n",
       "          0.63874588, 0.63874588, 0.65349544, 0.65680801, 0.64302264,\n",
       "          0.63874588, 0.64302264, 0.65349544, 0.65349544, 0.63874588,\n",
       "          0.63874588, 0.64302264, 0.64302264, 0.63874588, 0.65680801,\n",
       "          0.64302264, 0.65349544, 0.63874588, 0.63874588, 0.64302264,\n",
       "          0.65680801, 0.65680801, 0.65349544, 0.63874588, 0.64302264,\n",
       "          0.65349544, 0.65680801, 0.65680801, 0.65680801, 0.63874588,\n",
       "          0.63874588, 0.64302264, 0.65349544, 0.65680801, 0.63874588,\n",
       "          0.65680801, 0.64302264, 0.63874588, 0.65680801, 0.64302264,\n",
       "          0.65680801, 0.65680801, 0.65680801, 0.65349544, 0.63874588,\n",
       "          0.63874588, 0.63874588, 0.65349544, 0.65349544, 0.65349544,\n",
       "          0.63874588, 0.65680801, 0.65680801, 0.65680801, 0.65680801,\n",
       "          0.63874588, 0.63874588, 0.65349544, 0.65349544, 0.64302264,\n",
       "          0.63874588, 0.64302264, 0.65680801, 0.65349544, 0.63874588,\n",
       "          0.65349544, 0.65680801, 0.65349544, 0.65349544, 0.65349544,\n",
       "          0.64302264, 0.63874588, 0.63874588, 0.65349544, 0.63874588,\n",
       "          0.65349544, 0.64302264, 0.65680801, 0.65349544, 0.64302264,\n",
       "          0.64302264, 0.64302264, 0.65349544, 0.64302264, 0.63874588,\n",
       "          0.65680801, 0.65349544, 0.65680801, 0.65349544, 0.63874588,\n",
       "          0.65680801, 0.63874588, 0.64302264, 0.64302264, 0.64302264,\n",
       "          0.65349544, 0.65680801, 0.65349544, 0.64302264, 0.65349544,\n",
       "          0.63874588, 0.64302264, 0.65349544, 0.65349544, 0.65680801,\n",
       "          0.65349544, 0.65349544, 0.65349544, 0.63874588, 0.63874588,\n",
       "          0.65680801, 0.65680801, 0.65349544, 0.65349544, 0.65349544,\n",
       "          0.65349544, 0.65680801, 0.65349544, 0.65680801, 0.65680801,\n",
       "          0.63874588, 0.64302264, 0.63874588, 0.64302264, 0.65349544,\n",
       "          0.65349544, 0.65680801, 0.63874588, 0.65349544, 0.65680801,\n",
       "          0.65349544, 0.65680801, 0.65680801, 0.65680801, 0.65680801,\n",
       "          0.63874588, 0.64302264, 0.64302264, 0.63874588, 0.65680801,\n",
       "          0.65680801, 0.64302264, 0.65349544, 0.64302264, 0.63874588,\n",
       "          0.65680801, 0.64302264, 0.65680801, 0.64302264, 0.65349544,\n",
       "          0.63874588, 0.63874588, 0.64302264, 0.64302264, 0.65349544,\n",
       "          0.65349544, 0.65680801, 0.63874588, 0.65349544, 0.64302264,\n",
       "          0.65349544, 0.63874588, 0.64302264, 0.63874588, 0.64302264,\n",
       "          0.65349544, 0.65349544, 0.65680801, 0.64302264, 0.65680801,\n",
       "          0.64302264, 0.63874588, 0.65349544, 0.65680801, 0.65680801,\n",
       "          0.63874588, 0.65349544, 0.65680801, 0.64302264, 0.65680801,\n",
       "          0.63874588, 0.65680801, 0.65349544, 0.64302264, 0.64302264,\n",
       "          0.65349544, 0.65680801, 0.64302264, 0.65680801, 0.65349544,\n",
       "          0.65349544, 0.65680801, 0.65680801, 0.65680801, 0.63874588,\n",
       "          0.64302264, 0.65680801, 0.63874588, 0.65680801, 0.63874588,\n",
       "          0.64302264, 0.65680801, 0.65349544, 0.65349544, 0.65680801,\n",
       "          0.65680801, 0.63874588, 0.65349544, 0.65349544, 0.65680801,\n",
       "          0.64302264, 0.64302264, 0.65680801, 0.65680801, 0.63874588,\n",
       "          0.65680801, 0.65680801, 0.65680801, 0.64302264, 0.64302264,\n",
       "          0.63874588, 0.65349544, 0.63874588, 0.63874588, 0.63874588,\n",
       "          0.64302264, 0.64302264, 0.63874588, 0.65349544, 0.65349544,\n",
       "          0.65349544, 0.63874588, 0.63874588, 0.65349544, 0.65349544,\n",
       "          0.65680801, 0.64302264, 0.65680801, 0.63874588, 0.65349544,\n",
       "          0.63874588, 0.65349544, 0.65680801, 0.65680801, 0.63874588]])},\n",
       " array([[0.63874588, 0.65680801, 0.64302264, 0.65349544, 0.65680801,\n",
       "         0.65349544, 0.65680801, 0.64302264, 0.65349544, 0.64302264,\n",
       "         0.64302264, 0.65680801, 0.65680801, 0.64302264, 0.65680801,\n",
       "         0.64302264, 0.65680801, 0.64302264, 0.63874588, 0.64302264,\n",
       "         0.63874588, 0.63874588, 0.65680801, 0.65349544, 0.63874588,\n",
       "         0.63874588, 0.64302264, 0.65680801, 0.65349544, 0.63874588,\n",
       "         0.65349544, 0.63874588, 0.64302264, 0.65349544, 0.64302264,\n",
       "         0.65349544, 0.65680801, 0.65680801, 0.65680801, 0.65680801,\n",
       "         0.65349544, 0.63874588, 0.65349544, 0.65349544, 0.63874588,\n",
       "         0.64302264, 0.65349544, 0.64302264, 0.63874588, 0.65680801,\n",
       "         0.65349544, 0.64302264, 0.65349544, 0.63874588, 0.64302264,\n",
       "         0.65680801, 0.64302264, 0.63874588, 0.63874588, 0.65349544,\n",
       "         0.65680801, 0.64302264, 0.65349544, 0.64302264, 0.64302264,\n",
       "         0.63874588, 0.64302264, 0.64302264, 0.65680801, 0.63874588,\n",
       "         0.65680801, 0.63874588, 0.65680801, 0.65349544, 0.65680801,\n",
       "         0.65349544, 0.65349544, 0.64302264, 0.65680801, 0.65349544,\n",
       "         0.65680801, 0.65349544, 0.64302264, 0.65349544, 0.65680801,\n",
       "         0.64302264, 0.64302264, 0.65680801, 0.63874588, 0.63874588,\n",
       "         0.64302264, 0.63874588, 0.65680801, 0.65349544, 0.63874588,\n",
       "         0.64302264, 0.65349544, 0.64302264, 0.65680801, 0.65680801,\n",
       "         0.65680801, 0.65680801, 0.63874588, 0.63874588, 0.64302264,\n",
       "         0.65680801, 0.64302264, 0.65680801, 0.65349544, 0.65349544,\n",
       "         0.64302264, 0.65680801, 0.63874588, 0.64302264, 0.65349544,\n",
       "         0.63874588, 0.65349544, 0.65349544, 0.63874588, 0.63874588,\n",
       "         0.65349544, 0.63874588, 0.65349544, 0.63874588, 0.65349544,\n",
       "         0.64302264, 0.65680801, 0.63874588, 0.65349544, 0.63874588,\n",
       "         0.63874588, 0.64302264, 0.65680801, 0.63874588, 0.65680801,\n",
       "         0.64302264, 0.65349544, 0.64302264, 0.63874588, 0.64302264,\n",
       "         0.63874588, 0.64302264, 0.65680801, 0.63874588, 0.64302264,\n",
       "         0.65680801, 0.64302264, 0.64302264, 0.64302264, 0.65349544,\n",
       "         0.64302264, 0.63874588, 0.65680801, 0.64302264, 0.65349544,\n",
       "         0.63874588, 0.63874588, 0.65349544, 0.65680801, 0.64302264,\n",
       "         0.63874588, 0.64302264, 0.65349544, 0.65349544, 0.63874588,\n",
       "         0.63874588, 0.64302264, 0.64302264, 0.63874588, 0.65680801,\n",
       "         0.64302264, 0.65349544, 0.63874588, 0.63874588, 0.64302264,\n",
       "         0.65680801, 0.65680801, 0.65349544, 0.63874588, 0.64302264,\n",
       "         0.65349544, 0.65680801, 0.65680801, 0.65680801, 0.63874588,\n",
       "         0.63874588, 0.64302264, 0.65349544, 0.65680801, 0.63874588,\n",
       "         0.65680801, 0.64302264, 0.63874588, 0.65680801, 0.64302264,\n",
       "         0.65680801, 0.65680801, 0.65680801, 0.65349544, 0.63874588,\n",
       "         0.63874588, 0.63874588, 0.65349544, 0.65349544, 0.65349544,\n",
       "         0.63874588, 0.65680801, 0.65680801, 0.65680801, 0.65680801,\n",
       "         0.63874588, 0.63874588, 0.65349544, 0.65349544, 0.64302264,\n",
       "         0.63874588, 0.64302264, 0.65680801, 0.65349544, 0.63874588,\n",
       "         0.65349544, 0.65680801, 0.65349544, 0.65349544, 0.65349544,\n",
       "         0.64302264, 0.63874588, 0.63874588, 0.65349544, 0.63874588,\n",
       "         0.65349544, 0.64302264, 0.65680801, 0.65349544, 0.64302264,\n",
       "         0.64302264, 0.64302264, 0.65349544, 0.64302264, 0.63874588,\n",
       "         0.65680801, 0.65349544, 0.65680801, 0.65349544, 0.63874588,\n",
       "         0.65680801, 0.63874588, 0.64302264, 0.64302264, 0.64302264,\n",
       "         0.65349544, 0.65680801, 0.65349544, 0.64302264, 0.65349544,\n",
       "         0.63874588, 0.64302264, 0.65349544, 0.65349544, 0.65680801,\n",
       "         0.65349544, 0.65349544, 0.65349544, 0.63874588, 0.63874588,\n",
       "         0.65680801, 0.65680801, 0.65349544, 0.65349544, 0.65349544,\n",
       "         0.65349544, 0.65680801, 0.65349544, 0.65680801, 0.65680801,\n",
       "         0.63874588, 0.64302264, 0.63874588, 0.64302264, 0.65349544,\n",
       "         0.65349544, 0.65680801, 0.63874588, 0.65349544, 0.65680801,\n",
       "         0.65349544, 0.65680801, 0.65680801, 0.65680801, 0.65680801,\n",
       "         0.63874588, 0.64302264, 0.64302264, 0.63874588, 0.65680801,\n",
       "         0.65680801, 0.64302264, 0.65349544, 0.64302264, 0.63874588,\n",
       "         0.65680801, 0.64302264, 0.65680801, 0.64302264, 0.65349544,\n",
       "         0.63874588, 0.63874588, 0.64302264, 0.64302264, 0.65349544,\n",
       "         0.65349544, 0.65680801, 0.63874588, 0.65349544, 0.64302264,\n",
       "         0.65349544, 0.63874588, 0.64302264, 0.63874588, 0.64302264,\n",
       "         0.65349544, 0.65349544, 0.65680801, 0.64302264, 0.65680801,\n",
       "         0.64302264, 0.63874588, 0.65349544, 0.65680801, 0.65680801,\n",
       "         0.63874588, 0.65349544, 0.65680801, 0.64302264, 0.65680801,\n",
       "         0.63874588, 0.65680801, 0.65349544, 0.64302264, 0.64302264,\n",
       "         0.65349544, 0.65680801, 0.64302264, 0.65680801, 0.65349544,\n",
       "         0.65349544, 0.65680801, 0.65680801, 0.65680801, 0.63874588,\n",
       "         0.64302264, 0.65680801, 0.63874588, 0.65680801, 0.63874588,\n",
       "         0.64302264, 0.65680801, 0.65349544, 0.65349544, 0.65680801,\n",
       "         0.65680801, 0.63874588, 0.65349544, 0.65349544, 0.65680801,\n",
       "         0.64302264, 0.64302264, 0.65680801, 0.65680801, 0.63874588,\n",
       "         0.65680801, 0.65680801, 0.65680801, 0.64302264, 0.64302264,\n",
       "         0.63874588, 0.65349544, 0.63874588, 0.63874588, 0.63874588,\n",
       "         0.64302264, 0.64302264, 0.63874588, 0.65349544, 0.65349544,\n",
       "         0.65349544, 0.63874588, 0.63874588, 0.65349544, 0.65349544,\n",
       "         0.65680801, 0.64302264, 0.65680801, 0.63874588, 0.65349544,\n",
       "         0.63874588, 0.65349544, 0.65680801, 0.65680801, 0.63874588]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cache, a3 = forward(X, params)\n",
    "cache, a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_funct(A,Y):\n",
    "    \n",
    "    '''\n",
    "    Cost function\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    logprob = (Y * np.log(A) + (1-Y) * np.log(1-A))\n",
    "    #ensuite la cost\n",
    "    cost = -(np.sum(logprob))/m\n",
    "    #je veux que l'on me retourne un nombre et non pas un array\n",
    "    cost = np.squeeze(cost)\n",
    "    #être sur que j'ai la cost au bon format\n",
    "    assert(isinstance(cost,float))\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7365344574339591"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost = cost_funct(a3,Y)\n",
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(X, Y, cache, params, l_r):\n",
    "    \n",
    "    a3 = cache['a3']\n",
    "    a2 = cache['a2']\n",
    "    a1 = cache['a1']\n",
    "    w3 = params['w3']\n",
    "    w2 = params['w2']\n",
    "    w1 = params['w1']\n",
    "    b1 = params['b1']\n",
    "    b2 = params['b2']\n",
    "    b3 = params['b3']\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    dz3 = a3 - Y\n",
    "    dw3 = 1/m * np.dot(dz3, a2.T)\n",
    "    db3 = 1/m * np.sum(dz3, axis=1, keepdims=True)\n",
    "    \n",
    "    dz2 = (np.dot(w3.T, dz3)) * (1 - (a2**2))\n",
    "    dw2 = 1/m * np.dot(dz2, a1.T)\n",
    "    db2 = 1/m * np.sum(dz2, axis=1, keepdims=True)\n",
    "    \n",
    "    dz1 = (np.dot(w2.T, dz2)) * (1 - (a1**2)) \n",
    "    dw1 = 1/m * np.dot(dz1, X.T)\n",
    "    db1 = 1/m * np.sum(dz1, axis=1, keepdims=True)\n",
    "    \n",
    "    w1 = params['w1'] - l_r * dw1\n",
    "    b1 = params['b1'] - l_r * db1\n",
    "    w2 = params['w2'] - l_r * dw2\n",
    "    b2 = params['b2'] - l_r * db2\n",
    "    w3 = params['w3'] - l_r * dw3\n",
    "    b3 = params['b3'] - l_r * db3\n",
    "    \n",
    "    params['w1'] = w1\n",
    "    params['b1'] = b1\n",
    "    params['w2'] = w2\n",
    "    params['b2'] = b2\n",
    "    params['w3'] = w3\n",
    "    params['b3'] = b3\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'w1': array([[ 1.24451328,  0.28472377],\n",
       "        [ 0.69241826,  1.58465333],\n",
       "        [ 1.29810297, -0.69257866]]),\n",
       " 'w2': array([[ 0.5362968 , -0.09972512, -0.07078492],\n",
       "        [ 0.19279395,  0.0402112 ,  0.79770116],\n",
       "        [ 0.44615493,  0.07699146,  0.26253763]]),\n",
       " 'w3': array([[ 0.11145272,  0.76630528, -0.20728461]]),\n",
       " 'b1': array([[-0.01154205],\n",
       "        [-0.0017971 ],\n",
       "        [-0.03584539]]),\n",
       " 'b2': array([[-0.01874434],\n",
       "        [-0.06798177],\n",
       "        [ 0.01044611]]),\n",
       " 'b3': array([[-0.14334609]])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward(X, Y, cache, params, 1) # test backward function with learning rate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(Predictions, Labels):\n",
    "\n",
    "    \"\"\"\n",
    "    Predictions shape (1, m)\n",
    "    Labels shape (1, m)\n",
    "    \"\"\"\n",
    "    \n",
    "    n_correct = np.sum(Predictions == Labels)\n",
    "    n_total   = Predictions.shape[1]\n",
    "    \n",
    "    accuracy = n_correct / n_total\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(Y, Y) # test accuracy function with labels & labels (doit retourner 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(X,Y,n_x,n_h1,n_h2,n_y, print_freq=100):\n",
    "    \n",
    "    # Initialisation\n",
    "    params = init_params(n_x,n_h1,n_h2,n_y)\n",
    "    \n",
    "    # Iterations and Learning rate\n",
    "    num_iter = int(input('\\nHow many iterations ? '))\n",
    "    l_r = float(input('\\nLearning rate ? '))\n",
    "    \n",
    "    #Loops\n",
    "    for i in range(0, num_iter):\n",
    "        # Forward ==> Prediciton a3\n",
    "        cache, a3 = forward(X, params)\n",
    "        # Cost function\n",
    "        cost = cost_funct(a3, Y)\n",
    "        # Backward ==> Update parameters\n",
    "        params = backward(X, Y, cache, params, l_r)\n",
    "        \n",
    "        if i % print_freq == 0 :\n",
    "                print(f'\\nCost after iteration {i} : {cost}')\n",
    "            \n",
    "    Predictions = (a3 > 0.5) * 1.\n",
    "    print(f\"\\nTrain accuracy: \", accuracy(Predictions, Y))\n",
    "        \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1.shape = (3, 2)\n",
      "w2.shape = (3, 3)\n",
      "w3.shape = (1, 3)\n",
      "b1.shape = (3, 1)\n",
      "b2.shape = (3, 1)\n",
      "b3.shape = (1, 1)\n",
      "\n",
      "How many iterations ? 1000\n",
      "\n",
      "Learning rate ? 0.5\n",
      "\n",
      "Cost after iteration 0 : 0.7365344574339591\n",
      "\n",
      "Cost after iteration 100 : 0.6926344955938711\n",
      "\n",
      "Cost after iteration 200 : 0.690589820512279\n",
      "\n",
      "Cost after iteration 300 : 0.6797600745047302\n",
      "\n",
      "Cost after iteration 400 : 0.6226549769490068\n",
      "\n",
      "Cost after iteration 500 : 0.4351283130501834\n",
      "\n",
      "Cost after iteration 600 : 0.5895881361037388\n",
      "\n",
      "Cost after iteration 700 : 0.7520085807567476\n",
      "\n",
      "Cost after iteration 800 : 0.04779294016381861\n",
      "\n",
      "Cost after iteration 900 : 0.04780572115746409\n",
      "\n",
      "Train accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "params = nn_model(X,Y,n_x,n_h1,n_h2,n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
